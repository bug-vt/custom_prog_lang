%%
%% This is file `sample-manuscript.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `manuscript')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-manuscript.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%%
%% The first command in your LaTeX source must be the \documentclass command.
%%%% Small single column format, used for CIE, CSUR, DTRAP, JACM, JDIQ, JEA, JERIC, JETC, PACMCGIT, TAAS, TACCESS, TACO, TALG, TALLIP (formerly TALIP), TCPS, TDSCI, TEAC, TECS, TELO, THRI, TIIS, TIOT, TISSEC, TIST, TKDD, TMIS, TOCE, TOCHI, TOCL, TOCS, TOCT, TODAES, TODS, TOIS, TOIT, TOMACS, TOMM (formerly TOMCCAP), TOMPECS, TOMS, TOPC, TOPLAS, TOPS, TOS, TOSEM, TOSN, TQC, TRETS, TSAS, TSC, TSLP, TWEB.
% \documentclass[acmsmall]{acmart}

%%%% Large single column format, used for IMWUT, JOCCH, PACMPL, POMACS, TAP, PACMHCI
% \documentclass[acmlarge,screen]{acmart}

%%%% Large double column format, used for TOG
% \documentclass[acmtog, authorversion]{acmart}

%%%% Generic manuscript mode, required for submission
%%%% and peer review
\documentclass[manuscript,screen,nonacm]{acmart}
%% Fonts used in the template cannot be substituted; margin 
%% adjustments are not allowed.
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.

%% These commands are for a PROCEEDINGS abstract or paper.

%
%  Uncomment \acmBooktitle if th title of the proceedings is different
%  from ``Proceedings of ...''!
%


%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}

%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{CS 4974 Independent Study: Scripting language design and implementation}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Bug Lee}
\email{bug19@vt.edu}
\affiliation{%
  \institution{Virginia Tech}
  \city{Blacksburg}
  \state{Virginia}
  \country{USA}
  \postcode{24061}
}
\makeatletter
\let\@authorsaddresses\@empty
\makeatother

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Lee.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}

\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10011007.10011006.10011041</concept_id>
       <concept_desc>Software and its engineering~Compilers</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~Compilers}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Compiler, Assembler, Virtual Machine}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle
\section{Introduction}
Over the years, the complexity of compiler design has immensely increased. At the hardware level, there are more diverse and sophisticated instruction sets to consider. At the software level, complex optimization schemes have been introduced for maximal performance, in addition to different language paradigms. As a result, the complexity of the modern compiler design overshadows the fundamentals behind the language construction as well as making the steps between programming language and execution more mysterious. For this reason, this project focused on two aspects: (1) building a simplified version of each component used in programming language construction, and (2) understanding how each component works together to execute a custom programming language. This report describes the semester-long project of building a C-like (C subset) programming language from scratch. 

\section{Project Overview}
The project was broken down into 3 parts, ordered from lower level to higher level: Virtual Machine, Assembler, Compiler. Each level depends on the level right below it, except for Virtual Machine which is a standalone software.

\subsection{Virtual Machine}
The Virtual Machine mimics the generic single-cycle hardware processor. The following describes the similarity:
\begin{itemize}
    \item Load instructions from the executable to the instruction cache. 
    \item Load and store a value into runtime stack and keep track of stack frame using stack pointer and frame pointer.
    \item Use the return register to access the return value from a function.
    \item Use the instruction pointer to read and execute the next instruction.
    \item Execute one instruction in a single cycle.
\end{itemize}
However, since the Virtual Machine was implemented using C++ instead of transistors, it was flexible for more functionalities that are not available in generic hardware:
\begin{itemize}
    \item Include the function cache that load all the function information from the executable.
    \item Perform type resolution/casting/coercion during runtime.
\end{itemize}
The Virtual Machine support 36 instructions (see appendix). The instruction set for Virtual Machine was designed to follow the Complex Instruction Set Computing (CISC) methodology. This is to make the runtime environment faster: doing as much work as possible in C++ instead of leaving implementation to a slower custom language.

Overall, the role of the Virtual Machine is to set the first point of simplification. Even with the simpler instruction set, however, writing binary executables by hand would be a painful task. Which lead to the implementation of the assembler.

Note that the Virtual Machine design was adapted from the Varanese's XVM\cite{Varanese}. However, there are three major differences. First, the custom VM was coded in C++ instead of C. Secondly, unlike XVM, it was simplified to single-threaded and stand-alone software. Finally, 6 instructions for string concatenation and conditional jumps support in XVM were removed in the custom VM. Instead, 12 new instructions were added to the custom VM. 

\subsection{Assembler}
Like generic assemblers, the main functionality is to allow users to use mnemonics and numeric operands, which then get translated to binary executables. However, the custom assembler supports more advanced features and takes advantage of flexibility from the Virtual Machine:
\begin{itemize}
    \item Differentiate function and label. Use \textbf{func} directive and curly braces to define function. Automatically add \textbf{ret} instruction at the end of the function after assembling.
    \item Use \textbf{var} and \textbf{param} directives to define variables or arrays and automatically reserve space inside the stack.
    \item Support functional scope. 
    \item Direct support for string type.
    \item Support for basic string processing.
    \item Allow instruction to accept a string, variable, and element inside an array (absolute or variable index). Note that type checking is done by the Virtual Machine during the runtime.
\end{itemize}
However, the limitation of expressivity and tedium of controlling the runtime stack still made assembly language difficult to program with and error-prone. The compiler improves on this issue.

Note that the Assembler design was adapted from the Varanese's XASM\cite{Varanese}. However, there are three major differences compared to XASM. First, the custom assembler was coded in C++ instead of C. Secondly, the lexer for the custom assembler was implemented using regular expression and state machine whereas XASM used a brute force approach. Finally, the parser for the custom assembler resembles more closely to recursive descent more than the brute force parser for XASM. 

\subsection{Compiler}
The custom compiler was designed for C-like custom language, where the goal was to translate source code into assembly code targeted for the custom virtual machine. The compiler provides a subset of functionality that what C compiler can do, including:
\begin{itemize}
    \item Preprocess line and block comments
    \item Assignment, arithmetic, relational, and logical operations
    \item Static scoping using block
    \item Support for array
    \item Conditional statements
    \item Loops and break/continue statements
    \item User-defined functions 
    \item Pass by value and pass by pointer
    \item Support for native functions like time, random, print, and exit
\end{itemize}
On the other hand, the custom compiler also adds additional features:
\begin{itemize}
    \item Typeless language
    \item Array holding multiple different types of elements
    \item Direct support for string type
    \item Support for basic string processing
\end{itemize}
The compiler showcased the insight and science behind the introduction of programming languages. As the secret behind the magic black box was revealed, it was incredible to observe how a complex program can be translated into a handful of simple instructions.

Note that the compiler design was adapted from Nystrom JLox interpreter\cite{Nystrom}. However, there are four major differences. First, the custom compiler was coded in C++ instead of Java. Secondly, the custom compiler emits assembly code as an output whereas JLox interprets each statement on the spot. Thirdly, the custom compiler supports both variables and arrays whereas JLox only supports variables. Finally, the custom compiler supports both pass-by-value and pass-by-reference whereas JLox only supports pass-by-value.


\section{Virtual Machine}

\subsection{Runtime Stack}
The Virtual Machine simulates the runtime stack using the linked list. Each stack position can hold any value type (integer, float, stack index, table index, and register code) and increment by 1, resembling word addressable memory. All values were designed to fit inside a single stack position, simplifying stack access/management. 

\subsection{Execution Cycle}
The execution cycle begins by first loading the entry point from the executable. Once load the entry point, the Virtual Machine takes the following steps for each cycle, which resemble the execution cycle of the hardware processor:
\begin{itemize}
    \item Fetch instruction \\
	Read the instruction that the instruction pointer is pointing at.
    \item Decode opcode \\
	The type of instruction is determined by first reading the opcode. Then, the Virtual Machine calls the appropriate function by index into an array of function pointers.
    \item Resolve operand \\
	The type of operand must be resolved in this stage. As the goal is to support the typeless language, the source operand gets locally cast to the destination operand type. 
    \item Execute instruction \\
	Once the operands are resolved locally, the Virtual Machine executes the instruction's logic.
    \item Write back \\
	For many instructions, the destination operand (stack index or return value register) gets updated to the result of the execution stage. 
\end{itemize}

\subsection{Flexibility VS Performance}
The simpler instruction set came with a cost. The Virtual Machine itself is software that needs to translate virtual instruction to real instruction during execution. Therefore, multiple real instructions were generated under the hood to execute one virtual instruction. This was one tradeoff between flexibility and performance.

\section{Assembler}
Although adding the assembler between the compiler and virtual machine was not necessary, the assembler was added for two reasons: (1) to gain more experience in applying compiler theory with a simpler problem domain before implementing the compiler, and (2) to simplify the code generation step for the compiler. The assembler was divided into 3 parts in the following order: lexer, parser, and code generator.

\subsection{Lexer}
The lexer was the starting point of the assembler implementation, where it transforms the input character stream from the text file to the lexeme/token stream needed for the parser. The lexical analysis process was implemented using a state machine, where the following regular expressions define rules for grouping characters into a lexeme.

\begin{center}
\begin{tabular}{l l l}
    \hline
    State & & Regex \\
    \hline
    INT & $\rightarrow$ & [0-9]+ \\
    FLOAT & $\rightarrow$ & [0-9]?"."[0-9]+ \\
    IDENT & $\rightarrow$ & [a-zA-Z\_][a-zA-Z\_0-9]* \\
    DELIM & $\rightarrow$ & (":" | "[" | "]" | "," | "$\{$" | "$\}$" | "\textbackslash n" ) \\
    STRING & $\rightarrow$ & ``.*`` \\
    \hline
\end{tabular}
\end{center}

\subsection{Parser}
The parsing process was designed to complete in 2 passes. In the first pass, the parser record labels, identifiers, and function into corresponding tables. Instructions are ignored in the first pass. In the second pass, the parser evaluates the instruction. When an instruction hold operand of type labels, identifiers, or function, the operand gets replaced with the numeric value (either instruction address for labels/function or stack address for identifiers). 2 pass parsing was needed to address forward referencing.

The parser follows the top-down approach, resembling recursive descent parsing. However, due to the grammar structure of the assembly language, identifying the first token on the line was enough to determine the syntax and semantics of the line. When the first token is directive, the parser follows the grammar rules and recurses to the appropriate function. However, for most cases when the first token is an opcode, syntax and semantic analysis are simple as matching the grammar of the potential instruction with the grammar rule cached inside the instruction lookup table.

In the end, the parser output a linked list of instructions, string, and function tables that are used by the code generator to output binary executable.

\subsection{Code generator}
The code generator uses the linked list of instructions, string, and function tables outputted by the parser to generate a binary executable. The format of the binary executable is shown below.

\begin{center}
\begin{tabular}{| c | c |}
    \hline
    Header & ID \\
    ~ & Version major, Version minor \\
    ~ & Stack size \\
    ~ & Global data size \\
    ~ & Main function present flag \\
    ~ & Main function index \\
    \hline
    Instruction Stream & Stream size \\
    ~ & <opcode, op count, op type, op value, op offset ...> \\
    ~ & \vdots \\
    \hline
    String Table & Table size \\
    ~ & <string length, string> \\
    ~ & \vdots \\
    \hline
    Function Table & Table size \\
    ~ & <entry point, parameter count, local data size> \\
    ~ & \vdots \\
    \hline
\end{tabular}
\end{center}


\section{Compiler}
The compiler was divided into 5 parts in the following order: preprocessor, lexer, parser, semantic analyzer, and code emitter. The compiler reuse most of the lexer design from the assembler, but comment handling was delegated to the preprocessor. On the other hand, parser design needed a different strategy as the complexity of the grammar rules was more demanding. So, unlike the assembler parser, the compiler parser only takes care of syntax analysis and generates an almost ready-to-use Abstract syntax tree (AST) as an output. Then, the semantic analyzer performs semantic analysis and completes the AST. As the last step, the code emitter visits the completed AST in post-order traversal and generates assembly code corresponding to the visiting AST node.

\subsection{Preprocessor}
To simplify lexer design, the preprocessor was designed to handle line and block comments. For line comments, the preprocessor replaces any character starting from // to a newline character with white space. Similarly, for block comments, the preprocessor replaces any character starting from /* until the end of block comment */.

\subsection{Lexer}
Like the assembler lexer, it takes a character stream from the source text file and outputs the lexeme/token stream needed for the parser. The same strategy from the assembler lexer, building a state machine where state transitions are described with regular expression, was used for lexical analysis. The difference is that number of unique tokens that the compiler lexer needs to support is much greater than the assembler lexer.

\subsection{Parser}
There are two main functionalities of the parser: (1) perform syntax analysis and (2) construct AST that represents source code in a more structured form, but not quite ready for code emitter. Like assembler, identifying the first token in the statement was enough to determine the type of statement that the parser was parsing. The following BNF describes the grammar rules of the custom language. 

\begin{center}
\begin{tabular}{l l l}
    \hline
    Head & & Body \\
    \hline
    program & $\rightarrow$ & declaration* EOF \\
    declaration & $\rightarrow$ & func \\
    ~ & ~ & | var \\
    ~ & ~ & | statement ; \\
    func & $\rightarrow$ & "func" function ; \\
    var & $\rightarrow$ & "var" IDENT ("[" INT "]")? ( "=" expression )? ";" ; \\
    statement & $\rightarrow$ & exprStmt \\
    ~ & ~ & | forStmt \\
    ~ & ~ & | ifStmt \\
    ~ & ~ & | printStmt \\
    ~ & ~ & | returnStmt \\
    ~ & ~ & | whileStmt \\
    ~ & ~ & | gotoStmt \\
    ~ & ~ & | block ; \\
    exprStmt & $\rightarrow$ & expression ";" ; \\
    forStmt & $\rightarrow$ & "for" "(" ( var | exprStmt | ";" ) expression? ";" expressions? ")" statement ; \\
    ifStmt & $\rightarrow$ & "if" "(" expression ")" statement \\
    ~ & ~ & ( "else" statement )? ; \\
    printStmt & $\rightarrow$ & "print" expression ";" ; \\
    returnStmt & $\rightarrow$ & "return" expression? ";" ; \\
    whileStmt & $\rightarrow$ & "while" "(" expression ")" statement ; \\
    gotoStmt & $\rightarrow$ & ( "break" | "continue" ) ";" ; \\
    block & $\rightarrow$ & "$\{$" declaration* "$\}$" ; \\
    \hline
\end{tabular}
\end{center}

However, unlike the assembler parser, now the statements can be formed with expressions instead of all terminals. So, knowing the first token in the statement was no longer enough to disambiguate what remaining tokens must be within the statement. The precedence and associativity also added the complexity of disambiguating expressions to correct grammar rules. 
As a solution, the parser was designed to use the recursive descent technique. The following BNF describes the expression grammar rules of the custom language. 

\begin{center}
\begin{tabular}{l l l}
    \hline
    Head & & Body \\
    \hline
    expression & $\rightarrow$ & assignment ; \\
    assignment & $\rightarrow$ & ( IDENT | ARRAY ) "=" assignment \\
    ~ & ~ & | logic-or ; \\
    logic-or & $\rightarrow$ & logic-and ( "| |" logic-and )* ; \\
    logic-and & $\rightarrow$ & equality ( "\&\&" equality )* ; \\
    equality & $\rightarrow$ & comparison ( ("!=" | "==" ) comparison )* ; \\
    comparison & $\rightarrow$ & term ( (">" | ">=" | "<" | "<=" ) term )* ; \\
    term & $\rightarrow$ & factor ( ("-" | "+" ) factor )* ; \\
    factor & $\rightarrow$ & unary ( ("/" | "*" ) unary )* ; \\
    unary & $\rightarrow$ & ("!" | "-" ) unary | call ; \\
    call & $\rightarrow$ & ref "(" arguments? ")" ; \\
    ref & $\rightarrow$ &  "\&" IDENT | primary ; \\
    primary & $\rightarrow$ & "true" | "false" \\
    ~ & ~ & | INT | FLOAT | STRING | IDENT | ARRAY | "(" expression ")" ; \\
    \hline
\end{tabular}
\end{center}

The precedence is determined from the bottom to the top in the above rules since the recursive descent technique recurses down until it reaches the leaf node of the AST. The associativity is determined by the placement of an operator. Placing before the recursive production like unary makes the rule right-associative whereas placing after the recursive production makes the rule left-associative.

The above grammar rules were translated directly to the C++ functions using the following strategy:

\begin{center}
\begin{tabular}{|c|c|}
    \hline
    Grammar notation & Code representation \\
    \hline
    Terminal & Token to match \\
    Nonterminal & Function call to corresponding rule \\
    | & \textbf{if} or \textbf{switch} statement \\
    * or + & \textbf{while} or \textbf{for} loop \\
    ? & \textbf{if} statement \\
    \hline
\end{tabular}
\end{center}

When the parser parses through the source file, it simultaneously builds the AST. Each rule adds corresponding node representation to AST, shaping the AST exactly the same as how the file was parsed. In the end, the parser output an AST that describes the source code using the grammar rules shown above, almost ready for use by the code emitter. The semantic analyzer fills in the remaining gap.


\subsection{Semantic analyzer}
The semantic analyzer also has two main tasks: (1) finishing up AST construction started in the parser and (2) semantic analysis. Like the parser, both actions happen simultaneously. The semantic analyzer used the visitor pattern to walk through the AST statement by statement, visiting AST nodes in the post-order traversal. 

First, the semantic analyzer completes the AST construction by taking care of static scope resolution and dereferencing that could not be handled during the parsing phase. Static scope resolution allows custom language to declare the local variable with a name that was already declared from another scope. This was implemented by shadowing the symbol table described in the following steps:
\begin{enumerate}
    \item When the semantic analyzer visits the new block, it assigns a new symbol table to be used for the new scope, pushing behind the previous symbol table as a backup.
    \item Then, when the semantic analyzer verifies the scope of a variable, it always checks the innermost symbol table first. Move onto the symbol table next in line if the corresponding variable name was not found.
    \item Semantic analyzer record the variable scope (symbol table ID) inside the AST, which will be used by the code emitter later.
    \item Once the semantic analyzer finishes visiting the block, it removes the assigned symbol table for the block and restores the symbol table to the previous value. 
\end{enumerate}

On the other hand, dereferencing was needed to allow the pass-by-reference feature. Similar to C, the star "*" in front of the parameter indicates that the parameter is a pointer instead of a value and is recorded as a reference when added to the symbol table. When the semantic analyzer records the scope of a variable, it also checks if the variable is a reference. Dereferencing flag is set to true if the visiting AST node is the array index. This completes the AST construction to be used for the code emitter.

Now, for the semantic analysis, it is responsible for checking name conflict, validating the number of argument passing and arity of functions, and catching any incorrect usage of variables/arrays/functions. The semantic analyzer was designed to disallow name conflict between functions and variables to minimize the coding mistake caused by misusing the function as a variable or vice versa. The verification for name conflict is simple as whether the name was previously defined as a different type by looking up both function and symbol tables. The other verifications also use table lookup and follow similar steps.

\subsection{Code emitter}
The code emitter generates assembly code targeted for the custom virtual machine. Like a semantic analyzer, it uses the visitor design pattern to visit each AST node in the post-order traversal.
For simpler implementation, the code emitter was designed to follow the stack machine model. That is, it heavily utilizes stack to store intermediate results for each instruction. However, to make the generated code compatible with the custom assembler, three registers, \_t0, \_t1, and a return value register were used in addition to the stack. 

In the case of emitting code for expressions, the code emitter needed explicitly write the corresponding operation in assembly. For example, writing the binary expression takes the following steps: 
\begin{enumerate}
    \item Pop the operands from the top of the stack to \_t0
    \item Pop the operands from the top of the stack to \_t1
    \item Perform operation on \_t0 with \_t1 
    \item Push the \_t0 to the top of the stack
\end{enumerate}

On the other hand, emitting code for statements resembled more closely to the high-level counterpart. Most of the work was to think about what part of the code should be emitted first and where should be placed, whereas emitting process was simple as letting the code emitter recursively do the work. For example, writing a while statement takes the following steps. Note that the code for continue/break was omitted for a clearer view.
\begin{enumerate}
    \item Start label
    \item Let code emitter emit conditional expression
    \item Pop the top of the stack value to \_t0
    \item Jump to End label if \_t0 is false 
    \item Let code emitter emit body statement
    \item Jump to Start label
    \item End label 
\end{enumerate} 


\section{Test strategy}
For testing each part of the project, the C++ Catch2 framework and python unittest were used for automated regression testing. The main strategy was to employ Test Driven Development, where test suites and specifications were written first before fully developing the software\cite{OCW6.005}. Testing was divided into two categories for each project: unit testing and integration testing. See Appendix B for test cases.


\section{Benchmark results}

\begin{center}
\begin{tabular}{|c|c|c|c|}
    \hline
    Program & Input size & Custom language & Python \\
    \hline
    Fibonacci & 25 & 1.3913 seconds & 0.0345 seconds \\
    Insertion sort & 1000 & 2.1393 seconds & 0.0258 seconds \\
    Merge sort & 10000 & 2.3585 seconds & 0.0394 seconds \\
    \hline
\end{tabular}
\end{center}

\section{Limitations/Challenges}
Although the finished project satisfies all the functionality proposed in the syllabus, there are design choices that need improvement or even reconsideration. First, the compiler does not support array initialization nor initialize array size with variables. The current VM design, where array size must be known ahead to allocate enough space inside the stack frame, has hindered further extension of the array. Next, the current compilation process contains minor memory leaks. During debugging, several memory leaks were caught, such as not freeing the symbol table and AST after their usage, but not all memory leaks were fixed on time. Fortunately, no memory leaks were found inside the virtual machine, so running the executable generated by the compiler is found to be safe. Lastly, both compiler and runtime errors are too minimal to be useful for debugging the error. The syntax error output the error message with line and error location, whereas only error messages are available for semantic and runtime error. 


\section{Conclusions and Future work}
Despite the importance and rich history of compilers and programming languages, not many understand the mystery behind the compiler and how one can build their own. In this project, we have focused on building a simplified version of the virtual machine, assembler, and compiler to support C-like custom language. By end of the project, not only did I understand how each component worked together to translate a high-level language all the way down to bytecode, I became more confident in learning other programming languages as I gained a deeper understanding of both theory and implementation. 

The project has set a good foundation for future work and I have many ideas for the next step on virtual machine and compiler. The first idea is to make the custom programming language more friendly to work with by adding support for initializing an array with variables, a better mechanism for pass-by-reference, a way to import other source code, and outputting more helpful error messages. Another idea is to learn about compiler optimization. Extending the language features with first-class, closure, and object orientation is also at the top of the consideration.


%%
%% The acknowledgments section is defined using the "acks" environment
%% (and NOT an unnumbered section). This ensures the proper
%% identification of the section in the article metadata, and the
%% consistent spelling of the heading.
\begin{acks}
To Dr.Gulzar, for supervising the independent study and providing guidance.
\end{acks}

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{references}

%%
%% If your work has an appendix, this is the place to put it.
\appendix

\section{Instruction set}
\subsection{Memory}
\begin{center}
\begin{tabular}{|c|c|c|c|}
    \hline
    Instruction & Opcode & Operand count & Operands \\
    \hline
    mov & 0 & 2 & DESTINATION, SOURCE \\
    \hline
\end{tabular}
\end{center}

\subsection{Arithmetic}
\begin{center}
\begin{tabular}{|c|c|c|c|}
    \hline
    Instruction & Opcode & Operand count & Operands \\
    \hline
    add & 1 & 2 & DESTINATION, SOURCE \\
    sub & 2 & 2 & DESTINATION, SOURCE \\
    mul & 3 & 2 & DESTINATION, SOURCE \\
    div & 4 & 2 & DESTINATION, SOURCE \\
    mod & 5 & 2 & DESTINATION, SOURCE \\
    exp & 6 & 2 & DESTINATION, SOURCE \\
    neg & 7 & 1 & DESTINATION \\
    inc & 8 & 1 & DESTINATION \\
    dec & 9 & 1 & DESTINATION \\
    \hline
\end{tabular}
\end{center}

\subsection{Bitwise}
\subsection{String Processing}
\subsection{Conditional Branching}
\subsection{Stack Interface}
\subsection{Function Interface}
\subsection{Directives}

\section{Test suite}
\subsection{Virtual Machine}

\begin{center}
\begin{tabular}{|c|c|c|}
    \hline
    Test name & Type & Test Framework \\
    \hline
    Stack initialization & Unit & C++ Catch2 \\
    Stack getValue & Unit & C++ Catch2 \\
    Stack pushFrame & Unit & C++ Catch2 \\
    Stack popFrame & Unit & C++ Catch2 \\
    Nested function calls & Unit & C++ Catch2 \\
    Frame pointer correctness & Unit & C++ Catch2 \\
    Add & Integration & Python Unittest \\
    Mov & Integration & Python Unittest \\
    Call & Integration & Python Unittest \\
    NestedCall & Integration & Python Unittest \\
    BasicAdder & Integration & Python Unittest \\
    Example & Integration & Python Unittest \\
    Arithmetic & Integration & Python Unittest \\
    Bitwise & Integration & Python Unittest \\
    Branch & Integration & Python Unittest \\
    Jump & Integration & Python Unittest \\
    CmdLineArgs & Integration & Python Unittest \\
    Fibonacci & Integration & Python Unittest \\
    InsertionSort & Integration & Python Unittest \\
    Global & Integration & Python Unittest \\
    PassByRef & Integration & Python Unittest \\
    Pop & Integration & Python Unittest \\
    Concat & Integration & Python Unittest \\
    StringProcess & Integration & Python Unittest \\
    \hline
\end{tabular}
\end{center}

\subsection{Assembler}
\begin{center}
\begin{tabular}{|c|c|c|}
    \hline
    Test name & Type & Test Framework \\
    \hline
    Basic instruction lookup & Unit & C++ Catch2 \\
    Basic integer lexing & Unit & C++ Catch2 \\
    Basic float lexing & Unit & C++ Catch2 \\
    Negative intger/float lexing & Unit & C++ Catch2 \\
    Basic identifier lexing & Unit & C++ Catch2 \\
    Baisc array lexing & Unit & C++ Catch2 \\
    Lexing reserved word and instruction mnemonic & Unit & C++ Catch2 \\
    Basic delim lexing & Unit & C++ Catch2 \\
    Basic string lexing & Unit & C++ Catch2 \\
    String lexing with escape characters & Unit & C++ Catch2 \\
    Lexing comment & Unit & C++ Catch2 \\
    Lexing multi-line input & Unit & C++ Catch2 \\
    Peek next token & Unit & C++ Catch2 \\
    Lexing Invalid token & Unit & C++ Catch2 \\
    Lexing until EOF & Unit & C++ Catch2 \\
    Test displaying error & Unit & C++ Catch2 \\
    Lexing file & Unit & C++ Catch2 \\
    Basic function directive parsing & Unit & C++ Catch2 \\
    Function parsing error & Unit & C++ Catch2 \\
    Basic var/var[] parsing & Unit & C++ Catch2 \\
    var/var[] parsing error & Unit & C++ Catch2 \\
    Basic param parsing & Unit & C++ Catch2 \\
    param parsing error & Unit & C++ Catch2 \\
    Basic line label parsing & Unit & C++ Catch2 \\
    Basic instruction parsing & Unit & C++ Catch2 \\
    parsing global variable as operand & Unit & C++ Catch2 \\
    Test forward referencing & Unit & C++ Catch2 \\
    Instruction parsing error & Unit & C++ Catch2 \\
    Basic input parsing & Unit & C++ Catch2 \\
    Parsing file & Unit & C++ Catch2 \\
    Test function table & Unit & C++ Catch2 \\
    \hline
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|c|}
    \hline
    Test name & Type & Test Framework \\
    \hline
    Writing header & Integration & C++ Catch2 \\
    Writing a single instruction & Integration & C++ Catch2 \\
    Writing a instruction with float operand & Integration & C++ Catch2 \\
    Writing a print instruction & Integration & C++ Catch2 \\
    Writing a lw instruction & Integration & C++ Catch2 \\
    Writing a ref instruction & Integration & C++ Catch2 \\
    Using return value register & Integration & C++ Catch2 \\
    Writing branch instruction & Integration & C++ Catch2 \\
    Writing branch instruction with comparison & Integration & C++ Catch2 \\
    Writing string table & Integration & C++ Catch2 \\
    Writing function table & Integration & C++ Catch2 \\
    Writing multiple functions & Integration & C++ Catch2 \\
    \hline
\end{tabular}
\end{center}

\subsection{Compiler}
\begin{center}
\begin{tabular}{|c|c|c|}
    \hline
    Test name & Type & Test Framework \\
    \hline
    Removing line comment & Unit & C++ Catch2 \\
    Removing line comment2 & Unit & C++ Catch2 \\
    Removing line comment3 & Unit & C++ Catch2 \\
    Removing inner block comment & Unit & C++ Catch2 \\
    Removing multi-line block comment & Unit & C++ Catch2 \\
    Basic integer lexing & Unit & C++ Catch2 \\
    Basic float lexing & Unit & C++ Catch2 \\
    Negative intger/float lexing & Unit & C++ Catch2 \\
    Basic identifier lexing & Unit & C++ Catch2 \\
    Baisc array lexing & Unit & C++ Catch2 \\
    Lexing reserved word & Unit & C++ Catch2 \\
    lexing Operator & Unit & C++ Catch2 \\
    Lexing number, identifier, and operators & Unit & C++ Catch2 \\
    Basic delim lexing & Unit & C++ Catch2 \\
    Basic string lexing & Unit & C++ Catch2 \\
    Test string reach EOF without closing quote & Unit & C++ Catch2 \\
    String lexing with escape characters & Unit & C++ Catch2 \\
    Lexing line comment & Unit & C++ Catch2 \\
    Lexing block comment & Unit & C++ Catch2 \\
    Lexing multi-line input & Unit & C++ Catch2 \\
    Peek next token & Unit & C++ Catch2 \\
    Lexing Invalid token & Unit & C++ Catch2 \\
    Lexing until EOF & Unit & C++ Catch2 \\
    Test displaying error & Unit & C++ Catch2 \\
    Lexing file & Unit & C++ Catch2 \\
    Empty blocks parsing & Unit & C++ Catch2 \\
    Basic function declration parsing & Unit & C++ Catch2 \\
    Function declration parsing error & Unit & C++ Catch2 \\
    Function call parsing & Unit & C++ Catch2 \\
    Function call parsing error & Unit & C++ Catch2 \\
    Basic var/var[] parsing & Unit & C++ Catch2 \\
    var/var[] parsing error & Unit & C++ Catch2 \\
    parsing global variable as operand & Unit & C++ Catch2 \\
    Testing basic parsing & Unit & C++ Catch2 \\
    Testing parsing error & Unit & C++ Catch2 \\
    Testing emitting error & Unit & C++ Catch2 \\
    Parsing file & Unit & C++ Catch2 \\
    \hline
\end{tabular}
\end{center}

\begin{center}
\begin{tabular}{|c|c|c|}
    \hline
    Test name & Type & Test Framework \\
    \hline
    testAdd & Integration & Python unittest \\
    testArithmetic & Integration & Python unittest \\
    testComparison & Integration & Python unittest \\
    testGrouping & Integration & Python unittest \\
    testScope & Integration & Python unittest \\
    testString & Integration & Python unittest \\
    testIfThenElse & Integration & Python unittest \\
    testNestedControlFlow & Integration & Python unittest \\
    testLogical & Integration & Python unittest \\
    testWhileLoop & Integration & Python unittest \\
    testGoto & Integration & Python unittest \\
    testNestedWhile & Integration & Python unittest \\
    testForLoop & Integration & Python unittest \\
    testFuncCall & Integration & Python unittest \\
    testReturn & Integration & Python unittest \\
    testFib & Integration & Python unittest \\
    testArray & Integration & Python unittest \\
    testRef & Integration & Python unittest \\
    testArrayRef & Integration & Python unittest \\
    testRandInt & Integration & Python unittest \\
    testExit & Integration & Python unittest \\
    \hline
\end{tabular}
\end{center}

\end{document}
\endinput
%%
%% End of file `sample-authordraft.tex'.
